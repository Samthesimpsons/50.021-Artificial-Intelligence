{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI"
      },
      "source": [
        "# PyTorch - homework 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file that includes your answers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mJpzFaX0J6Zz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mHomework by Samuel Sim Wei Xuan, number: 1004657\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1004657\"\n",
        "student_name=\"Samuel Sim Wei Xuan\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_"
      },
      "source": [
        " ## Question 1 -- matrix multiplication\n",
        "\n",
        "Implement the following mathematical operation on both the CPU and GPU (use Google Colab or another cloud service if you don't have a GPU in your computer). Print:\n",
        "\n",
        "a) which type of GPU card you have and \n",
        "\n",
        "b) show the computation time for both CPU and GPU (using PyTorch). \n",
        "\n",
        "c) How much % fast is the GPU? \n",
        "\n",
        " The operation to implement is the dot product $C = B * A^T$\n",
        "\n",
        " whereby $A$ is a random matrix of size $20,000 \\times 1,000$ and $B$ is a random matrix of size $2,000 \\times 1,000$. In addition to the required information asked above:\n",
        " \n",
        " d) please also print the resulting two $C$ matrices (they should be the same btw). \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BINvhm-PLKak"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jun 16 15:05:48 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 511.79       Driver Version: 511.79       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   57C    P8    N/A /  N/A |      0MiB /  2048MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\samue\\anaconda3\\envs\\data_science\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU computational time = 0.5564229488372803s.\n",
            "GPU computational time = 0.7620043754577637s.\n",
            "The GPU is 73% faster than the CPU.\n",
            "tensor([[247.5575, 246.7191, 261.9646,  ..., 250.8572, 252.6265, 254.5060],\n",
            "        [247.7598, 248.5540, 265.0316,  ..., 253.0777, 257.2379, 260.2686],\n",
            "        [246.1667, 243.0087, 259.4931,  ..., 248.9215, 253.9141, 252.2600],\n",
            "        ...,\n",
            "        [251.3370, 247.6081, 268.7363,  ..., 257.6855, 260.7569, 263.1600],\n",
            "        [242.7777, 240.8331, 256.9476,  ..., 249.0210, 249.4253, 248.1706],\n",
            "        [249.0987, 256.3116, 268.3563,  ..., 258.3694, 259.2379, 264.0441]])\n",
            "tensor([[247.5574, 246.7191, 261.9647,  ..., 250.8573, 252.6266, 254.5061],\n",
            "        [247.7597, 248.5540, 265.0316,  ..., 253.0776, 257.2379, 260.2686],\n",
            "        [246.1667, 243.0087, 259.4932,  ..., 248.9217, 253.9141, 252.2600],\n",
            "        ...,\n",
            "        [251.3372, 247.6081, 268.7364,  ..., 257.6855, 260.7569, 263.1599],\n",
            "        [242.7777, 240.8331, 256.9472,  ..., 249.0209, 249.4251, 248.1706],\n",
            "        [249.0986, 256.3115, 268.3562,  ..., 258.3695, 259.2378, 264.0443]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# implement solution here\n",
        "\n",
        "# a) which type of GPU card you have and\n",
        "!nvidia-smi\n",
        "\n",
        "# b) show the computation time for both CPU and GPU (using PyTorch).\n",
        "import time\n",
        "import torch\n",
        "\n",
        "A = torch.rand(20000, 1000)\n",
        "A_T = torch.transpose(A,0,1)\n",
        "B = torch.rand(2000, 1000)\n",
        "\n",
        "cpu_start_time = time.time()\n",
        "cpu_result = torch.mm(B, A_T)\n",
        "cpu_end_time = time.time()\n",
        "cpu_time_elapsed = cpu_end_time - cpu_start_time\n",
        "print('CPU computational time = {}s.'.format(cpu_time_elapsed))\n",
        "\n",
        "gpu_start_time = time.time()\n",
        "gpu_result = torch.mm(B.cuda(), A_T.cuda())\n",
        "gpu_end_time = time.time()\n",
        "gpu_time_elapsed = gpu_end_time - gpu_start_time\n",
        "print('GPU computational time = {}s.'.format(gpu_time_elapsed))\n",
        "\n",
        "# c) How much % fast is the GPU?\n",
        "print(\"The GPU is {}% faster than the CPU.\".format(round(cpu_time_elapsed/gpu_time_elapsed*100),2))\n",
        "\n",
        "# d) please also print the resulting two  C  matrices (they should be the same btw).\n",
        "print(cpu_result)\n",
        "print(gpu_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJXmfT-yU3g"
      },
      "source": [
        "## Question 2 - grad\n",
        "\n",
        "\n",
        "Find the gradient (partial derivatives) of the function $g(w)$ below. \n",
        "\n",
        "Let  $w=[w_1,w_2]^T$\n",
        "\n",
        "Consider  $g(w)=2w_1w_2+w_2cos(w_1)$\n",
        "\n",
        "a) In PyTorch, compute:   $\\nabla g(w)$ \n",
        "\n",
        " and verify that $\\nabla g([\\pi,1])=[2,2\\piâˆ’1]^T$ using the grad function, whereby the first position is the partial for $w_1$ and the second position is the partial for $w_2$. \n",
        "\n",
        "b) You can also write a function to manually calculate these partial derivatives! You can review your differential equations math at [here](https://www.wolframalpha.com/input/?i=derivative+y+cos%28x%29) and implement this as a second function below to verify that it comes to the same solution. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pLjz6_LKt4sc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Gradient of g(w) = [2.0, 5.2831854820251465]\n",
            "Manual Gradient of g(w) = [2.0, 5.2831854820251465]\n"
          ]
        }
      ],
      "source": [
        "# write your solution here\n",
        "import math\n",
        "\n",
        "# a) In PyTorch, compute del g(w)\n",
        "def g(w): \n",
        "    return 2*w[0]*w[1] + w[1]*torch.cos(w[0])\n",
        "\n",
        "input_w = torch.tensor([math.pi, 1.0], requires_grad=True)\n",
        "output_g = g(input_w)\n",
        "output_g.backward()\n",
        "\n",
        "print('PyTorch Gradient of g(w) = {}'.format([input_w.grad[0].item(),input_w.grad[1].item()]))\n",
        "\n",
        "# b) Manual calculation of the gradient of g(w)\n",
        "def partial_derivatives(w): \n",
        "    return [2*w[1] - w[1]*torch.sin(w[0]), 2*w[0] + torch.cos(w[0])]\n",
        "\n",
        "derivatives = partial_derivatives(input_w)\n",
        "\n",
        "print('Manual Gradient of g(w) = {}'.format([derivatives[0].item(), derivatives[1].item()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJwP6ur8LKjD"
      },
      "source": [
        "## Question 3 - dance hit song prediction\n",
        "\n",
        "Implement logistic regression in PyTorch for the following dance hit song prediction training dataset: \n",
        "https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
        "\n",
        " * Input variables: a number of audio features (most already standardized so don't worry about that)\n",
        " * Target variable: Topclass1030: \n",
        "   * 1 means it was a top 10 hit song; \n",
        "   * 0 means it never went above top 30 position.\n",
        "\n",
        "This dataset is derived from my paper on dance hit song prediction, for full description of features have a look at https://arxiv.org/abs/1905.08076. \n",
        "\n",
        "Print the evolution of the loss every few epochs and train the model until it converges. \n",
        " \n",
        " After training the logistic regression model, calculate the prediction accuracy on the test set: \n",
        " https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VyRP6bl8t4Wc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/2000], Loss: 0.6791\n",
            "Epoch [100/2000], Loss: 0.5735\n",
            "Epoch [200/2000], Loss: 0.5562\n",
            "Epoch [300/2000], Loss: 0.5280\n",
            "Epoch [400/2000], Loss: 0.5051\n",
            "Epoch [500/2000], Loss: 0.4885\n",
            "Epoch [600/2000], Loss: 0.4765\n",
            "Epoch [700/2000], Loss: 0.4679\n",
            "Epoch [800/2000], Loss: 0.4617\n",
            "Epoch [900/2000], Loss: 0.4571\n",
            "Epoch [1000/2000], Loss: 0.4538\n",
            "Epoch [1100/2000], Loss: 0.4514\n",
            "Epoch [1200/2000], Loss: 0.4498\n",
            "Epoch [1300/2000], Loss: 0.4487\n",
            "Epoch [1400/2000], Loss: 0.4481\n",
            "Epoch [1500/2000], Loss: 0.4478\n",
            "Epoch [1600/2000], Loss: 0.4479\n",
            "Epoch [1700/2000], Loss: 0.4482\n",
            "Epoch [1800/2000], Loss: 0.4487\n",
            "Epoch [1900/2000], Loss: 0.4493\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# load data\n",
        "dataset = pd.read_csv('https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv')\n",
        "output = dataset['Topclass1030']\n",
        "input = dataset.drop('Topclass1030', axis=1)\n",
        "\n",
        "# define logistic regression model\n",
        "class Logistic_Regression(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(Logistic_Regression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.linear(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "model = Logistic_Regression(input.shape[1], 1)\n",
        "# if torch.cuda.is_available():\n",
        "#     model = model.cuda()\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "\n",
        "# train model\n",
        "num_epochs = 2000\n",
        "num_steps = input.shape[0]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for step in range(num_steps):\n",
        "        batch_x = torch.tensor(input.loc[step].values).float()\n",
        "        batch_y = torch.tensor([output.loc[step]]).float()\n",
        "\n",
        "        # if torch.cuda.is_available():\n",
        "        #     batch_x = batch_x.cuda()\n",
        "        #     batch_y = batch_y.cuda()\n",
        "\n",
        "        optimizer.zero_grad() \n",
        "        y_hat = model(batch_x) \n",
        "\n",
        "        loss = loss_function(y_hat, batch_y) \n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw4yfGoGuChe"
      },
      "source": [
        "Run the below code to test the accuracy of your model on the training set: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L88WmKtMt5gH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Positives: 43, True Negatives: 17\n",
            "False Positives: 12, False Negatives: 7\n",
            "Class specific accuracy of correctly predicting a hit song is 0.86\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "\n",
        "test = pd.read_csv('https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv')\n",
        "labels = test.iloc[:,-1]\n",
        "test = test.drop('Topclass1030', axis=1)\n",
        "testdata = torch.Tensor(test.values)\n",
        "testlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "TP = 0\n",
        "TN = 0\n",
        "FN = 0\n",
        "FP = 0\n",
        "\n",
        "for i in range(0, testdata.size()[0]): \n",
        "  # print(testdata[i].size())\n",
        "  Xtest = torch.Tensor(testdata[i])\n",
        "  y_hat = model(Xtest)\n",
        "  \n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  if (prediction == testlabels[i]):\n",
        "    if (prediction == 1):\n",
        "      TP += 1\n",
        "    else: \n",
        "      TN += 1\n",
        "\n",
        "  else:\n",
        "    if (prediction == 1):\n",
        "      FP += 1\n",
        "    else: \n",
        "      FN += 1\n",
        "\n",
        "print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "rate = TP/(FN+TP)\n",
        "print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Week 5 - AI homework - torch intro",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "ec18ae124fb7ff17ee29ebf19e741c06b30197736ff00dfba64476edf53b661f"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('data_science')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
